{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "728f75d3",
   "metadata": {},
   "source": [
    "# Modelado — Clasificación de Viabilidad (tabular)\n",
    "Notebook para entrenamiento, validación y selección del mejor modelo con datos tabulares procesados.\n",
    "\n",
    "**Entrada:** `data/processed/startups_sintetico_1000_processed.csv`\n",
    "\n",
    "**Métricas:** ROC AUC (principal), F1, Precisión, Recall, Accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7d3528",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Imports y setup ===\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import (roc_auc_score, f1_score, precision_score, recall_score, accuracy_score,\n",
    "                             confusion_matrix, RocCurveDisplay, PrecisionRecallDisplay)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "\n",
    "processed_path = Path(\"data/processed/startups_sintetico_1000_processed.csv\")\n",
    "assert processed_path.exists(), \"No se encuentra el procesado. Ejecuta el notebook de exploración/limpieza primero.\"\n",
    "df = pd.read_csv(processed_path, encoding=\"utf-8\")\n",
    "print(df.shape)\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada6d314",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Preparación de X, y ===\n",
    "TARGET_COL = \"viabilidad\"\n",
    "assert TARGET_COL in df.columns, \"Falta la columna objetivo 'viabilidad'\"\n",
    "drop_cols = []\n",
    "\n",
    "# Evitar fuga y ruido: no usar texto ni la cruda si existe una versión robusta\n",
    "if \"descripcion\" in df.columns:\n",
    "    drop_cols.append(\"descripcion\")\n",
    "if \"presencia_redes\" in df.columns and \"intensidad_redes\" in df.columns:\n",
    "    drop_cols.append(\"presencia_redes\")\n",
    "\n",
    "X = df.drop(columns=[TARGET_COL] + drop_cols)\n",
    "y = df[TARGET_COL].astype(int)\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "print(\"X shape:\", X.shape, \"| Num feats:\", len(num_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c607fc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Partición 70/15/15 y CV ===\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, stratify=y, random_state=RANDOM_STATE)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.50, stratify=y_temp, random_state=RANDOM_STATE)\n",
    "print(\"Splits ->\", X_train.shape, X_valid.shape, X_test.shape)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "def evaluate_model(clf, Xv, yv, name=\"model\"):\n",
    "    # scores probabilísticos\n",
    "    if hasattr(clf, \"predict_proba\"):\n",
    "        scores = clf.predict_proba(Xv)[:,1]\n",
    "    elif hasattr(clf, \"decision_function\"):\n",
    "        scores = clf.decision_function(Xv)\n",
    "    else:\n",
    "        scores = clf.predict(Xv)\n",
    "    yhat = (scores >= 0.5).astype(int)\n",
    "    metrics = {\n",
    "        \"roc_auc\": roc_auc_score(yv, scores),\n",
    "        \"f1\": f1_score(yv, yhat),\n",
    "        \"precision\": precision_score(yv, yhat, zero_division=0),\n",
    "        \"recall\": recall_score(yv, yhat),\n",
    "        \"accuracy\": accuracy_score(yv, yhat),\n",
    "    }\n",
    "    print(f\"[{name}] AUC={metrics['roc_auc']:.3f} | F1={metrics['f1']:.3f} | P={metrics['precision']:.3f} | R={metrics['recall']:.3f} | Acc={metrics['accuracy']:.3f}\")\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f9d0ec",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b2ec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dummy = DummyClassifier(strategy=\"stratified\", random_state=RANDOM_STATE).fit(X_train, y_train)\n",
    "_ = evaluate_model(dummy, X_valid, y_valid, \"Dummy\")\n",
    "\n",
    "logit = Pipeline([(\"scaler\", StandardScaler(with_mean=False)),\n",
    "                  (\"clf\", LogisticRegression(max_iter=250, random_state=RANDOM_STATE))]).fit(X_train, y_train)\n",
    "_ = evaluate_model(logit, X_valid, y_valid, \"LogReg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3b4458",
   "metadata": {},
   "source": [
    "## Modelos candidatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe9b9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tree = DecisionTreeClassifier(random_state=RANDOM_STATE).fit(X_train, y_train)\n",
    "_ = evaluate_model(tree, X_valid, y_valid, \"DecisionTree\")\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=300, random_state=RANDOM_STATE, n_jobs=-1).fit(X_train, y_train)\n",
    "_ = evaluate_model(rf, X_valid, y_valid, \"RandomForest\")\n",
    "\n",
    "hgb = HistGradientBoostingClassifier(max_iter=300, learning_rate=0.1, random_state=RANDOM_STATE).fit(X_train, y_train)\n",
    "_ = evaluate_model(hgb, X_valid, y_valid, \"HGB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c28a5e9",
   "metadata": {},
   "source": [
    "## Comparación con CV (ROC AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb4d75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for name, model in {\"LogReg\":logit, \"Tree\":tree, \"RF\":rf, \"HGB\":hgb}.items():\n",
    "    scores = cross_val_score(model, X_train, y_train, scoring=\"roc_auc\", cv=cv, n_jobs=-1)\n",
    "    print(f\"{name:7s} CV AUC: {scores.mean():.3f} ± {scores.std():.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b40f263",
   "metadata": {},
   "source": [
    "## Tuning básico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dea9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# HGB: RandomizedSearch liviano\n",
    "param_dist_hgb = {\n",
    "    \"learning_rate\":[0.03,0.05,0.1,0.2],\n",
    "    \"max_depth\":[None,3,5,7],\n",
    "    \"l2_regularization\":[0.0,0.1,0.5,1.0],\n",
    "    \"max_iter\":[200,300,500]\n",
    "}\n",
    "rs_hgb = RandomizedSearchCV(HistGradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "                            param_distributions=param_dist_hgb, n_iter=20, scoring=\"roc_auc\",\n",
    "                            cv=cv, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "rs_hgb.fit(X_train, y_train)\n",
    "print(\"Best HGB:\", rs_hgb.best_params_)\n",
    "_ = evaluate_model(rs_hgb.best_estimator_, X_valid, y_valid, \"HGB_tuned\")\n",
    "\n",
    "# RF: Grid pequeño\n",
    "param_grid_rf = {\"n_estimators\":[200,400], \"max_depth\":[None,6,12], \"max_features\":[\"sqrt\",0.5]}\n",
    "gs_rf = GridSearchCV(RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1),\n",
    "                     param_grid=param_grid_rf, scoring=\"roc_auc\", cv=cv, n_jobs=-1)\n",
    "gs_rf.fit(X_train, y_train)\n",
    "print(\"Best RF:\", gs_rf.best_params_)\n",
    "_ = evaluate_model(gs_rf.best_estimator_, X_valid, y_valid, \"RF_tuned\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fc5a40",
   "metadata": {},
   "source": [
    "## Selección final y evaluación en test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5557f59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "finals = {\"HGB_tuned\": rs_hgb.best_estimator_, \"RF_tuned\": gs_rf.best_estimator_}\n",
    "best_name, best_model, best_auc = None, None, -np.inf\n",
    "for name, m in finals.items():\n",
    "    met = evaluate_model(m, X_valid, y_valid, name)\n",
    "    if met[\"roc_auc\"] > best_auc:\n",
    "        best_auc, best_name, best_model = met[\"roc_auc\"], name, m\n",
    "\n",
    "print(f\"Mejor en valid: {best_name} AUC={best_auc:.3f}\")\n",
    "\n",
    "# Reentrena con train+valid\n",
    "best_model.fit(pd.concat([X_train,X_valid]), pd.concat([y_train,y_valid]))\n",
    "\n",
    "# Test\n",
    "if hasattr(best_model, \"predict_proba\"):\n",
    "    scores_test = best_model.predict_proba(X_test)[:,1]\n",
    "elif hasattr(best_model, \"decision_function\"):\n",
    "    scores_test = best_model.decision_function(X_test)\n",
    "else:\n",
    "    scores_test = best_model.predict(X_test)\n",
    "\n",
    "y_pred05 = (scores_test>=0.5).astype(int)\n",
    "\n",
    "print(\"=== Test @0.5 ===\")\n",
    "print(\"AUC:\", roc_auc_score(y_test, scores_test))\n",
    "print(\"F1:\", f1_score(y_test, y_pred05), \"Prec:\", precision_score(y_test, y_pred05), \"Rec:\", recall_score(y_test, y_pred05), \"Acc:\", accuracy_score(y_test, y_pred05))\n",
    "print(\"Matriz de confusión\\n\", confusion_matrix(y_test, y_pred05))\n",
    "\n",
    "# Curvas\n",
    "_ = RocCurveDisplay.from_predictions(y_test, scores_test)\n",
    "plt.title(\"ROC — Test\")\n",
    "plt.show()\n",
    "\n",
    "_ = PrecisionRecallDisplay.from_predictions(y_test, scores_test)\n",
    "plt.title(\"Precision-Recall — Test\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
